# 问题及解决

## 问题一：absl-py库 元类冲突

Ruiqin-Huang: 出现了元类冲突，这个和下面/root/miniconda3/envs/howl/lib/python3.6/site-packages/absl/flags/_argument_parser.py中的这个类的定义错误有关吗

(howl) root@autodl-container-734740b388-15d28f59:~/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl# python -m training.run.train -i datasets/water/positive datasets/water/negative --model res8 --workspace workspaces/water-res8-250124-0
Traceback (most recent call last):
  File "/root/miniconda3/envs/howl/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/root/miniconda3/envs/howl/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl/training/run/train.py", line 32, in <module>
    from howl.workspace import Workspace
  File "/root/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl/howl/workspace.py", line 8, in <module>
    from torch.utils.tensorboard import SummaryWriter
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py", line 13, in <module>
    from .writer import FileWriter, SummaryWriter  # noqa: F401
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/torch/utils/tensorboard/writer.py", line 13, in <module>
    from tensorboard.summary.writer.event_file_writer import EventFileWriter
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/summary/__init__.py", line 22, in <module>
    from tensorboard.summary import v1  # noqa: F401
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/summary/v1.py", line 23, in <module>
    from tensorboard.plugins.histogram import summary as _histogram_summary
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/plugins/histogram/summary.py", line 35, in <module>
    from tensorboard.plugins.histogram import summary_v2
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/plugins/histogram/summary_v2.py", line 35, in <module>
    from tensorboard.util import tensor_util
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/util/tensor_util.py", line 20, in <module>
    from tensorboard.compat.tensorflow_stub import dtypes, compat, tensor_shape
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/__init__.py", line 25, in <module>
    from . import app  # noqa
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/app.py", line 21, in <module>
    from . import flags
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/flags.py", line 25, in <module>
    from absl.flags import *  # pylint: disable=wildcard-import
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/absl/flags/__init__.py", line 35, in <module>
    from absl.flags import _argument_parser
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/absl/flags/_argument_parser.py", line 86, in <module>
    class ArgumentParser(Generic[_T], metaclass=_ArgumentParserCache):
TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases

class ArgumentParser(Generic[_T], metaclass=_ArgumentParserCache):
# class ArgumentParser(metaclass=GenericMeta):
  """Base class used to parse and convert arguments.

  The :meth:`parse` method checks to make sure that the string argument is a
  legal value and convert it to a native type.  If the value cannot be
  converted, it should throw a ``ValueError`` exception with a human
  readable explanation of why the value is illegal.

  Subclasses should also define a syntactic_help string which may be
  presented to the user to describe the form of the legal values.

  Argument parser classes must be stateless, since instances are cached
  and shared between flags. Initializer arguments are allowed, but all
  member variables must be derived from initializer arguments only.
  """

  syntactic_help: Text = ''

  def parse(self, argument: Text) -> Optional[_T]:
    """Parses the string argument and returns the native value.

    By default it returns its argument unmodified.

    Args:
      argument: string argument passed in the commandline.

    Raises:
      ValueError: Raised when it fails to parse the argument.
      TypeError: Raised when the argument has the wrong type.

    Returns:
      The parsed value in native type.
    """
    if not isinstance(argument, str):
      raise TypeError('flag value must be a string, found "{}"'.format(
          type(argument)))
    return argument

  def flag_type(self) -> Text:
    """Returns a string representing the type of the flag."""
    return 'string'

  def _custom_xml_dom_elements(
      self, doc: minidom.Document
  ) -> List[minidom.Element]:
    """Returns a list of minidom.Element to add additional flag information.

    Args:
      doc: minidom.Document, the DOM document it should create nodes from.
    """
    del doc  # Unused.
    return []

GitHub Copilot: 让我分析一下这个元类冲突问题：

### 问题分析
1. 错误出现在定义

ArgumentParser

类时
2. 冲突发生在

Generic[_T]

和

_ArgumentParserCache

这两个元类之间
3. 错误提示表明派生类的元类必须是其所有基类元类的(非严格)子类

### 解决方案步骤
1. 需要确保两个元类兼容
2. 可以通过以下几种方式修改:
   - 修改

_ArgumentParserCache

继承自`GenericMeta`
   - 或者移除

Generic[_T]

的泛型支持
   - 或者使用Python 3.7+的新方式处理泛型

### 建议修复
修改

_ArgumentParserCache

类定义，使其继承自`GenericMeta`:

```python


from typing import GenericMeta

class _ArgumentParserCache(GenericMeta):
    # ...existing code...
    pass

class ArgumentParser(Generic[_T], metaclass=_ArgumentParserCache):
    # ...existing code...
```

或者简化为:

```python


class ArgumentParser(metaclass=_ArgumentParserCache):
    # ...existing code...
```

建议采用第二种简化方案，因为:
1. 移除泛型支持不会影响主要功能
2. 避免了复杂的元类继承关系
3. 更容易维护和理解

如果一定需要泛型支持，建议升级到Python 3.7+版本，因为新版本对泛型和元类的处理有了改进。

Ruiqin-Huang: 修改后，又出现了新的问题：(howl) root@autodl-container-734740b388-15d28f59:~/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl# python -m training.run.train -i datasets/water/positive datasets/water/negative --model res8 --workspace workspaces/water-res8-250124-0
Traceback (most recent call last):
  File "/root/miniconda3/envs/howl/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/root/miniconda3/envs/howl/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl/training/run/train.py", line 32, in <module>
    from howl.workspace import Workspace
  File "/root/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl/howl/workspace.py", line 8, in <module>
    from torch.utils.tensorboard import SummaryWriter
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py", line 13, in <module>
    from .writer import FileWriter, SummaryWriter  # noqa: F401
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/torch/utils/tensorboard/writer.py", line 13, in <module>
    from tensorboard.summary.writer.event_file_writer import EventFileWriter
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/summary/__init__.py", line 22, in <module>
    from tensorboard.summary import v1  # noqa: F401
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/summary/v1.py", line 23, in <module>
    from tensorboard.plugins.histogram import summary as _histogram_summary
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/plugins/histogram/summary.py", line 35, in <module>
    from tensorboard.plugins.histogram import summary_v2
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/plugins/histogram/summary_v2.py", line 35, in <module>
    from tensorboard.util import tensor_util
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/util/tensor_util.py", line 20, in <module>
    from tensorboard.compat.tensorflow_stub import dtypes, compat, tensor_shape
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/__init__.py", line 25, in <module>
    from . import app  # noqa
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/app.py", line 21, in <module>
    from . import flags
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/flags.py", line 25, in <module>
    from absl.flags import *  # pylint: disable=wildcard-import
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/absl/flags/__init__.py", line 35, in <module>
    from absl.flags import _argument_parser
  File "/root/miniconda3/envs/howl/lib/python3.6/site-packages/absl/flags/_argument_parser.py", line 147, in <module>
    class NumericParser(ArgumentParser[_N]):
TypeError: '_ArgumentParserCache' object is not subscriptable


GitHub Copilot: ### 问题分析步骤

1. 新错误显示

_ArgumentParserCache

对象不可下标访问
2. 错误出现在`NumericParser`类定义中尝试使用

ArgumentParser[_N]


3. 根本原因是移除了泛型支持但仍在尝试使用泛型特性

### 解决方案步骤

1. 需要恢复泛型支持
2. 正确设置元类继承关系
3. 确保Python版本兼容性

### 代码修改建议

```python


from typing import Generic, GenericMeta

class _ArgumentParserCache(GenericMeta):
    """Cache for argument parsers."""
    _instances = {}
    
    def __call__(cls, *args, **kwargs):
        key = (cls, args, tuple(sorted(kwargs.items())))
        try:
            return cls._instances[key]
        except KeyError:
            instance = super().__call__(*args, **kwargs)
            cls._instances[key] = instance
            return instance

class ArgumentParser(Generic[_T], metaclass=_ArgumentParserCache):
    # ...existing code...
```

### 替代方案

如果上述修改仍有问题，可以考虑降级tensorboard版本：

```bash
pip uninstall tensorboard
pip install tensorboard==1.15.0
```

或升级Python环境到3.7+：

```bash
conda create -n howl_new python=3.7
conda activate howl_new
pip install -r requirements.txt
```

建议采用升级Python版本的方案，因为Python 3.6已经停止维护，而且新版本对泛型和元类有更好的支持。

最终解决方案，验证有效！
1. 卸载absl-py及tensorboard,使用mamba install "tensorboard==2.8.0"重新安装absl-py及tensorboard(会在安装tensorboard的同时安装absl-py==2.0.0)

2. 修改/root/miniconda3/envs/howl/lib/python3.6/site-packages/absl/flags/_argument_parser.py
# 250124,为了解决元类冲突，尝试修改
# /root/miniconda3/envs/howl/lib/python3.6/site-packages/absl/flags/_argument_parser.py, line 82, 源代码如下:
################################################
# class ArgumentParser(Generic[_T], metaclass=_ArgumentParserCache):
################################################

################################################
# 以下为添加内容 #
from typing import Generic, GenericMeta

class _ArgumentParserCache(GenericMeta):
    """Cache for argument parsers."""
    _instances = {}
    
    def __call__(cls, *args, **kwargs):
        key = (cls, args, tuple(sorted(kwargs.items())))
        try:
            return cls._instances[key]
        except KeyError:
            instance = super().__call__(*args, **kwargs)
            cls._instances[key] = instance
            return instance
          
class ArgumentParser(Generic[_T], metaclass=_ArgumentParserCache):
################################################




## 问题二：torch版本与3080Ti不兼容

执行训练代码
```bash
(howl) root@autodl-container-734740b388-15d28f59:~/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl# python -m training.run.train -i datasets/water/positive datasets/water/negative --model res8 --workspace workspaces/water-res8-250124-0
```

UserWarning: 
NVIDIA GeForce RTX 3080 Ti with CUDA capability sm_86 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.

1. 根据错误信息发现 PyTorch 安装版本与 RTX 3080 Ti (sm_86) 不兼容
2. 当前 PyTorch 仅支持 sm_37、sm_50、sm_60、sm_70
3. 需要修改脚本强制使用 CPU 或更新 PyTorch

关键报错：RuntimeError: CUDA error: no kernel image is available for execution on the device

根据你提供的命令
```bash
python -c "import torch; print(f'CUDA is available?: {torch.cuda.is_available()}\nCUDA version: {torch.version.cuda}\ndevice: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else "None"}')"
```
输出：
  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
CUDA is available?: True
CUDA version: 10.2
device: NVIDIA GeForce RTX 3080 Ti
以及警告信息 NVIDIA GeForce RTX 3080 Ti with CUDA capability sm_86 is not compatible with the current PyTorch installation.，我们可以得出以下结论：

虽然torch.cuda.is_available() 返回 True，表明CUDA是可用的，并且系统检测到了你的 NVIDIA GeForce RTX 3080 Ti 显卡，但是你的PyTorch版本 (CUDA 10.2) 并不支持 RTX 3080 Ti 的 sm_86 架构。 因此，尽管CUDA可用，但PyTorch无法有效利用你的3080 Ti进行加速计算。 你看到的“可用”指的是CUDA驱动程序已安装且系统可以检测到GPU，但这并不意味着PyTorch可以利用它。 你需要安装一个支持sm_86架构的PyTorch版本。

简而言之，CUDA可用性本身并不能保证PyTorch能够充分利用你的GPU。 你需要检查PyTorch版本与你的GPU的CUDA Capability的兼容性。 警告信息已经明确指出你的PyTorch版本与你的GPU不兼容。

解决方案：
0. 验证cuda是否可用
```bash
python -c "import torch; print(f'CUDA is available?: {torch.cuda.is_available()}\nCUDA version: {torch.version.cuda}\ndevice: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else "None"}')"
# 注意：该方法只能测试CUDA是否可用，不能测试PyTorch是否支持你的GPU
```
```bash
python -c "import torch; print(torch.zeros(1).cuda())"
# 如果没有报错，说明PyTorch支持你的GPU
```

1. 创建新的conda环境howl_train，专用于howl训练（未尝试过）
```bash
conda create -n howl_train python=3.10.4
conda activate howl_train
# 安装pytorch相关包
mamba install pytorch==2.0.0 torchvision==0.15.0 torchaudio==2.0.0 pytorch-cuda=11.8 -c pytorch -c nvidiamamba install pytorch==2.0.0 torchvision==0.15.0 torchaudio==2.0.0 pytorch-cuda=11.8 -c pytorch -c nvidia
# 安装训练相关依赖requirements_training.txt
pip install -r requirements_training.txt
```
2. 网络搜索得知，其实已有安装版本torch能支持CUDA11.3但是实际上安装的CUDA版本是10.2，所以需要升级CUDA版本 (成功解决问题！)

- 参考博客 https://www.cnblogs.com/happyamyhope/p/16404790.html 的指导
- 要点：卸载torch, torchaudio, torchvision后，重新安装torch==1.10.1cu113的包
```bash
mamba install pytorch==1.10.0 torchvision torchaudio cudatoolkit=11.3
```

  Updating specs:

   - pytorch==1.10.0
   - torchvision
   - torchaudio
   - cudatoolkit=11.3


  Package           Version  Build                        Channel                                                       Size
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
  Install:
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

  + cudatoolkit      11.3.1  hb98b00a_13                  mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge      633MB
  + intel-openmp   2022.1.0  h9e868ea_3769                mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main                5MB
  + liblapacke        3.8.0  16_mkl                       mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge       11kB
  + libstdcxx        14.2.0  hc0a3c3a_1                   mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge     Cached
  + libuv            1.50.0  hb9d3cd8_0                   mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge      891kB
  + mkl              2020.2  256                          mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main              145MB
  + ninja            1.12.1  h297d8ca_0                   mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge        2MB
  + pytorch          1.10.0  py3.6_cuda11.3_cudnn8.2.0_0  mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch            1GB
  + pytorch-cpu       1.1.0  py36he1b5a44_0               mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge       53MB
  + pytorch-mutex       1.0  cuda                         mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch            3kB
  + torchaudio       0.10.0  py36_cu113                   mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch            5MB
  + torchvision      0.10.1  py36h2de9e49_0_cpu           mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge        7MB

  Upgrade:
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

  - blas                1.1  openblas                     mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge     Cached
  + blas               2.16  mkl                          mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge       11kB
  - libstdcxx-ng     11.2.0  h1234567_1                   mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main             Cached
  + libstdcxx-ng     14.2.0  h4852527_1                   mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge     Cached
  - scipy             1.5.2  py36habc2bb6_0               mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main             Cached
  + scipy             1.5.3  py36h976291a_0               mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge       20MB

  Downgrade:
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

  - libblas           3.9.0  8_openblas                   mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge     Cached
  + libblas           3.8.0  16_mkl                       mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge       11kB
  - libcblas          3.9.0  8_openblas                   mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge     Cached
  + libcblas          3.8.0  16_mkl                       mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge       11kB
  - liblapack         3.9.0  8_openblas                   mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge     Cached
  + liblapack         3.8.0  16_mkl                       mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge       11kB

  Summary:

  Install: 12 packages
  Upgrade: 3 packages
  Downgrade: 3 packages

  Total download: 2GB

- 运行成功！
```bash
2025-01-25 11:05:19,964 INFO info(85) Howl Settings:
	_cache:
		cache_size: 128144
	_dataset:
		dataset_path: None
	_training:
		seed: 0
		vocab: ['water']
		num_epochs: 70
		num_labels: 2
		learning_rate: 0.01
		device: cuda:0
		batch_size: 16
		lr_decay: 0.955
		max_window_size_seconds: 0.5
		eval_window_size_seconds: 0.75
		eval_stride_size_seconds: 0.063
		weight_decay: 1e-05
		convert_static: False
		objective: frame
		token_type: word
		phone_dictionary: None
		use_noise_dataset: False
		noise_dataset_path: None
	_inference_engine:
		inference_weights: None
		inference_sequence: [0]
		inference_window_ms: 2000.0
		smoothing_window_ms: 50.0
		tolerance_window_ms: 500.0
		inference_threshold: 0.0
	_audio:
		sample_rate: 16000
		use_mono: True
	_resource:
		cpu_count: 24
	_audio_transform:
		num_fft: 512
		num_mels: 40
		sample_rate: 16000
		hop_length: 200
		use_meyda_spectrogram: False

Training:   0%|                                                                                                                                                      | 0/70 [00:00<?, ?it/s]
```

## 问题三：训练过程 GPU占用率为0，但显存占用率较高，仅CPU在进行计算？

针对/root/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl/training/run/train.py文件，进行修改

### 分析步骤
1. 检查当前状态
2. 分析可能原因
3. 提供解决方案

### 可能原因
1. **数据加载瓶颈**:
- 数据预处理和加载在CPU上进行
- `DataLoader`的`num_workers=0`（默认值）导致单线程加载数据
- 这会导致GPU等待CPU提供数据

2. **数据转换未优化**:
```python
# 当前代码中的转换操作
audio_length = audio_transform.compute_lengths(batch.lengths)
zmuv_audio_data = zmuv_transform(audio_transform(batch.audio_data))
augmented_audio_data = spectrogram_augmentations(zmuv_audio_data)
```

### 建议修复
```python


# 1. 修改DataLoader，增加worker数量
train_dl = StandardAudioDataLoaderBuilder(ww_train_ds, collate_fn=audio_augmentations).build(
    batch_size=SETTINGS.training.batch_size,
    num_workers=4,  # 增加worker数量
    pin_memory=True  # 启用pin_memory加速数据传输
)

# 2. 提前将数据转移到GPU
audio_length = audio_transform.compute_lengths(batch.lengths).to(device)
audio_data = batch.audio_data.to(device)
zmuv_audio_data = zmuv_transform(audio_transform(audio_data))
augmented_audio_data = spectrogram_augmentations(zmuv_audio_data)

# 3. 设置CUDA线程数
torch.cuda.set_per_process_memory_fraction(0.8)  # 限制显存使用比例
torch.backends.cudnn.benchmark = True  # 启用cuDNN自动调优
```

### 验证优化效果
```python
# 添加性能监控代码
from torch.utils.benchmark import Timer

def profile_batch_processing():
    start_event = torch.cuda.Event(enable_timing=True)
    end_event = torch.cuda.Event(enable_timing=True)
    
    start_event.record()
    # 你的训练代码
    end_event.record()
    
    torch.cuda.synchronize()
    return start_event.elapsed_time(end_event)
```

这些修改应该能提高GPU利用率和训练速度。如果问题仍然存在，建议使用`nvprof`或

torch.profiler

进行更详细的性能分析。

解决方案：应该是我的判断失误？其实GPU正常，根据训练设置的输出，"training"使用了"cuda:0"(虽然"resource"中只有"cpu:24")

## 问题：Test negative写入文件时编码出错

Dev positive: 100%|##############################################################################################| 27/27 [00:34<00:00,  1.27s/it, mcc=0.0, c=ConfusionMatrix(tp=14, fp=0, tn=0
2025-01-25 16:24:31,999 INFO info(85) ConfusionMatrix(tp=14, fp=0, tn=0, fn=13)##################################| 27/27 [00:34<00:00,  1.29s/it, mcc=0.0, c=ConfusionMatrix(tp=14, fp=0, tn=0
Training: 100%|###############################################################################################################################| 15/15 [3:26:05<00:00, 824.34s/it, loss=0.134]
2025-01-25 17:21:01,100 INFO heading(79) >  Model evaluation
Dev positive: 100%|###############################################################################################| 27/27 [00:03<00:00,  8.50it/s, mcc=0.0, c=ConfusionMatrix(tp=18, fp=0, tn=
2025-01-25 17:21:04,283 INFO info(85) ConfusionMatrix(tp=18, fp=0, tn=0, fn=9)
Dev negative: 100%|##########################################################################################| 409/409 [08:48<00:00,  1.29s/it, mcc=0.0, c=ConfusionMatrix(tp=0, fp=133, tn=27
2025-01-25 17:29:53,166 INFO info(85) ConfusionMatrix(tp=0, fp=133, tn=276, fn=0)
Test positive: 100%|#############################################################################################| 38/38 [00:48<00:00,  1.27s/it, mcc=0.0, c=ConfusionMatrix(tp=27, fp=0, tn=0
2025-01-25 17:30:41,248 INFO info(85) ConfusionMatrix(tp=27, fp=0, tn=0, fn=11)
Test negative:   7%|######8                                                                                      | 29/392 [00:40<08:26,  1.40s/it, mcc=0.0, c=ConfusionMatrix(tp=0, fp=3, tn=2
Traceback (most recent call last):
  File "/root/miniconda3/envs/howl/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/root/miniconda3/envs/howl/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl/training/run/train.py", line 342, in <module>
    main()
  File "/root/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl/training/run/train.py", line 337, in main
    do_evaluate()
  File "/root/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl/training/run/train.py", line 104, in do_evaluate
    evaluate_engine(ww_test_neg_ds, "Test negative", positive_set=False)
  File "/root/autodl-tmp/DHG-Workspace-hrq-AutoDL/Research_on_Low-Cost_Custom_Voice_Wake-Up_Based_on_Voice_Cloning/baselines/KWS/howl/training/run/train.py", line 78, in evaluate_engine
    f"{ex.metadata.transcription}\t{int(seq_present)}\t{int(positive_set)}\t{ex.metadata.path}\n"
UnicodeEncodeError: 'ascii' codec can't encode character '\u2019' in position 34: ordinal not in range(128)

## 问题四：使用training.run.stitch_vocab_samples生成拼接唤醒词样本时，from pocketsphinx import AudioFile，ImportError: cannot import name 'AudioFile'

pocketsphinx是一个开源的音频转文字工具

使用pip show pocketsphinx显示版本时，发现pocketsphinx库not found，但是conda list中又包含pocketsphinx（因为pocketsphinx是从mamba install安装的）

解决方法：使用mamba uninstall写在现有8.0.0版本，使用pip install pocketsphinx安装5.0.0版本，问题解决（注意：使用pip install安装过程中会报错，请忽略）

## 评估阈值问题 threshold issue

Problem related to the evaluation threshold of wake-up word detection: Why, when setting the threshold to 0.0, according to the code in howl/howl/model/inference.py:

```Python
if max_prob < self.threshold:
        max_label = self.negative_label
```

all samples with prediction probability (probability of being predicted as a positive sample of the wake-up word?) < 0.0 should be classified as negative. Since the probability >= 0, theoretically all samples should be classified as positive, i.e., fn=tp=0. However, according to the hey_fire_fox experiment, when the threshold is 0.0, tn=2428, fn=2. The model still retains the ability to distinguish between negative samples. What causes this issue? Could it be related to OOV (Out-of-Vocabulary) classification? Or is it related to rounding errors?

line | eval_dataset | threshold | tp | tn | fp | fn
-- | -- | -- | -- | -- | --
1 | Dev positive | 0.0 | 74 | 0 | 0 | 2
2 | Dev negative | 0.0 | 0 | 2428 | 103 | 0
3 | Dev noisy positive | 0.0 | 69 | 0 | 0 | 7
4 | Dev noisy negative | 0.0 | 0 | 2468 | 63 | 0
5 | Test positive | 0.0 | 47 | 0 | 0 | 7
6 | Test negative | 0.0 | 0 | 2399 | 105 | 0
7 | Test noisy positive | 0.0 | 45 | 0 | 0 | 9
8 | Test noisy negative | 0.0 | 0 | 2442 | 62 | 0

**关键点和分析：**

1.  **`_append_probability_frame`：** 这个方法至关重要。它获取单个帧的原始模型输出（每个类的概率），并将其附加到 `self.pred_history` 中。它 *不会* 立即应用阈值。它只是存储概率。

2.  **`_get_prediction`：** 此方法是阈值处理发生的地方。它在 `self.pred_history` 中存储的 *帧窗口* 上运行。它首先删除过时的条目，然后 *在时间窗口内* 获取每个类的最大概率。*只有这样*，它才将 `max_prob` 与 `self.threshold` 进行比较。

3.  **`infer`（两个类）：** `infer` 方法为每个帧（或帧窗口）调用 `_append_probability_frame`。它们不会直接使用阈值。阈值仅在稍后 `_get_prediction` 中确定时间窗口的“最终”标签时使用。

4.  **阈值为 0.0：** 你有理由感到困惑。当阈值为 0.0 时，条件 `max_prob <= self.threshold` *应该* 始终为假（或由于浮点限制而非常接近）。`max_prob` 表示特定类在时间窗口内的最大概率。概率是非负的。那么，如何才能将任何东西归类为负类呢？

**缺失的部分：负类和着色**

代码具有 `negative_label` 和 `coloring` 机制，它们提供了关键勘误信息。

*   **`negative_label`：** 这是在满足阈值时分配的标签。它从上下文中初始化。
*   **`coloring`：** `coloring` 对象（如果存在）是一个映射。它用于重新映射类索引。`max_label = self.coloring.color_map.get(max_label, self.negative_label)` 这一行至关重要。如果 `max_label` 不在 `color_map` 中，它将默认为 `self.negative_label`。

**差异解释：**

问题可能是由于 `coloring` 逻辑，`negative_label` 本身是在检查阈值 *之前* 分配的。

以下是 `hey_fire_fox` 实验中 *可能* 发生的情况的细分：

1.  **模型预测：** 模型预测每个类的概率，包括负类。

2.  **确定最大概率：** `_get_prediction` 找到 *当前时间窗口内* 具有最高概率的类 (`max_label`)。

3.  **着色检查：** 代码检查 `max_label` 是否在 `coloring.color_map` 中。

4.  **默认为负类：** 如果 `max_label` *不在* `coloring.color_map` 中（这对于负样本或 OOV 来说很有可能），则 *无论 `max_prob` 是什么*，`max_label` 都会立即设置为 `self.negative_label`。

5.  **阈值检查（通常跳过）：** 如果 `coloring` 逻辑已经分配了 `negative_label`，则对于这些样本，比较 `max_prob <= self.threshold` 就变得无关紧要了。标签已经根据 `coloring` 逻辑分配。

**为什么当阈值为 0.0 时 `tn=2428`，`fn=2`？**

*   **真阴性 (tn=2428)：** 许多负样本可能被正确地归类为负类，*不是* 因为阈值比较，而是因为它们最初预测的 `max_label` 未在 `coloring.color_map` 中找到，导致其默认为 `negative_label`。

*   **假阴性 (fn=2)：** 两个假阴性可能发生是因为，即使阈值 *应该* 允许它们为正（因为阈值为 0.0），`coloring` 逻辑可能首先将它们分配为负类。可能还有其他原因。

**OOV 和着色：**

OOV 可能是重要因素。顾名思义，OOV 在模型的输出中没有得到很好的表示。很可能 `coloring` 逻辑旨在通过显式将它们（或它们最相似的类）映射到 `negative_label` 来处理 OOV。

**总之：** 阈值 0.0 具有误导性。`coloring` 逻辑是负类分配的主要驱动因素，尤其是对于 OOV，可能对于许多常规负样本也是如此。在这些情况下，阈值比较可能会被有效地绕过。

**建议：**

要完全理解该行为，你需要：

1.  **检查 `coloring` 对象：** 查看它如何映射（或不映射）类索引。这将揭示哪些类默认分配了负标签。

2.  **记录 `max_prob`：** 在阈值检查 *之前* 记录 `max_prob` 的值。这将确认是否甚至为负样本达到了阈值比较。

3.  **简化或删除着色：** 暂时禁用或简化 `coloring` 逻辑以隔离阈值的影响。这将让你更清楚地了解阈值 *应该* 如何工作。

通过分析这些方面，你应该能够准确地解释观察到的行为。

### color map中的标签重映射

当然，这是对我的回答的中文翻译：

**`LabelColoring` 机制：**

`LabelColoring` 类的设计目的是管理标签（表示类的整数）和颜色（也是整数）之间的映射。它用于重新映射或重新着色标签，主要用于可视化，或者可能用于处理像 OOV 这样的特殊情况。

以下是关键部分的细分：

1.  **`color_map`：** 这是映射的核心。键是标签（整数），值是相应的颜色（整数）。

2.  **`color_counter` 和 `label_counter`：** 这些用于在未明确提供颜色和标签时自动分配颜色和标签。它们有助于确保使用唯一的颜色和标签。

3.  **`append_label(label, color=None)`：** 此方法将标签-颜色映射添加到 `color_map`。

    *   如果标签已经存在，它会检查提供的颜色是否与现有颜色匹配。如果未提供颜色，则使用现有的颜色。这可以防止意外的重新分配。
    *   如果标签是新的，它会分配一个颜色。如果提供了颜色，则使用该颜色；否则，它使用 `color_counter` 生成一个新颜色。

4.  **`_inc_color_counter(color=None)`：** 帮助程序递增 `color_counter` 并分配颜色。

5.  **`extend_sequence(size, color=None)`：** 这很有趣。它将 *一系列* 标签添加到 `color_map`，所有标签都具有相同的颜色。这可能用于将相关标签组合在一起（例如，单词的子词单元或音素），以进行可视化或其他目的。

6.  **`sequential_coloring(num_labels)`：** 一种类方法，用于创建 `LabelColoring`，其中标签映射到连续的颜色。

**与 OOV 处理的关系：**

`LabelColoring` 类本身 *不* 直接处理 OOV。它是一种用于 *重新映射* 标签的机制。与 OOV 的连接在于它在 `InferenceEngine` 中如何 *使用*。

以下是它可能在 OOV 处理中扮演的角色：

1.  **OOV 检测（隐式）：** 模型可能会隐式检测 OOV。例如，如果输入序列包含一个 OOV 词，则模型对已知类的输出概率可能较低或不确定。预测的 argmax 可能指向一个默认的或“未知”的类。

2.  **标签重映射：** `InferenceEngine` 的 `coloring` 对象（`LabelColoring` 的一个实例）在 `_get_prediction` 中使用。关键行是：

    ```python
    max_label = self.coloring.color_map.get(max_label, self.negative_label)
    ```

    这一行说：“在 `coloring.color_map` 中查找 `max_label`（具有最高概率的类）。如果找到，则使用关联的颜色作为新标签。*如果找不到*，则使用 `self.negative_label`。”

3.  **OOV 作为负类：** 关键是 OOV（以及其他可能的低置信度预测）*不* 可能在 `color_map` 中。因此，当遇到 OOV 时，`get()` 方法将返回默认值，即 `self.negative_label`。

**本质上：** `LabelColoring` 用于将可能与 OOV 关联的标签（因为它们不在 `color_map` 中）映射到指定的 `negative_label`。这是一种后处理形式，用于处理模型对 OOV 的不确定性。模型可能不会明确地将某些内容 *标记* 为 OOV，但如果其预测的标签不在 `color_map` 中，则 `LabelColoring` 会有效地将其视为 OOV。

**示例：**

假设你的 `color_map` 只包含已知词的映射（例如，“fire”、“fox”）。如果输入包含一个像“florp”这样的 OOV 词，模型可能会在其词汇表上产生一些概率分布。假设最高概率是针对代表“fire”的类。但是，由于“florp”是一个 OOV，因此标签“fire”（或 fire 的索引是什么）*将不会* 在 `color_map` 中。然后，`get()` 方法将返回 `self.negative_label`，从而有效地将“florp”（以及任何其他未知词）归类为负类。

**总之：** `LabelColoring` 是一种标签重映射机制。它用于将可能与 OOV 关联的标签（因为它们不在 `color_map` 中）映射到 `negative_label`。这是一种通过将 OOV 视为属于特殊的“负”或“未知”类别来隐式处理 OOV 的方法。

